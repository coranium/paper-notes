# NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING

How do we determine model architecture? Usually no principled method to do this. NAS uses recurrent neural nets to generate model architecture, then improve it with reinforcement learning. This is used to create CNNs and recurrent cells, so seems to be quite flexible.

The RL framework contains the following key ideas:
- Represent model architecture as a variable length string so that this can be generated by RNN (Controller)
- Train a neural network based using the created arch, evaluate the accuracy of this model.
- Accuracy obtained is the reward signal for the controller network. This updates the controller through a policy gradient method
- Over time, controller network will assign higher probabilities to architectures that produce high accuracy.

A great idea, but seems to be very iterative and time consuming. I think there are alot of papers that improve on this, but this is prolly one of the OG's in investigating how we create neural net architectures. 

**NOTE** Policy gradient method is needed (RL part of this) as the reward value, accuracy of generated NN is non-differentiable W.R.T the controller RNN. Need to read more on how this works and RL in general.
